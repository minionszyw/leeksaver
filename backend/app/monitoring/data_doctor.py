"""
æ•°æ®åŒ»ç”Ÿ - æ•°æ®å¥åº·å·¡æ£€ç³»ç»Ÿ (Ultra é—­ç¯ç‰ˆ)

é›†æˆï¼šå…¨é‡åˆ†è¯Š -> RCA æº¯æº -> ç†”æ–­ä¿æŠ¤ -> ç‰©ç†æ¸…ç† -> æ™ºèƒ½è‡ªæ„ˆã€‚
"""

from datetime import date, timedelta, datetime
from dataclasses import dataclass
from typing import List, Dict, Set, Any

from sqlalchemy import select, func, and_, distinct, text, delete

from app.core.database import get_db_session
from app.core.logging import get_logger
from app.models.stock import Stock
from app.models.market_data import DailyQuote
from app.models.calendar import TradingCalendar
from app.models.sync_error import SyncError

logger = get_logger(__name__)


@dataclass
class HealthCheckResult:
    """å·¡æ£€ç»“æœ"""

    metric_name: str
    status: str  # "healthy" | "warning" | "critical"
    value: float
    threshold: float
    message: str
    details: dict | None = None


class DataDoctor:
    """æ•°æ®å¥åº·å·¡æ£€ç³»ç»Ÿ"""

    def __init__(self):
        self.results: List[HealthCheckResult] = []
        self.missing_codes: Set[str] = set()
        self.corrupted_codes: Set[str] = set()
        self.stubborn_codes: Set[str] = set() # é¡½ç–¾æ ‡çš„ (å¤šæ¬¡ä¿®å¤å¤±è´¥)

    async def run_daily_health_check(self) -> List[HealthCheckResult]:
        """
        æ‰§è¡Œå…¨é‡æ•°æ®è´¨é‡å·¡æ£€ä¸è‡ªåŠ¨ä¿®å¤é—­ç¯
        """
        logger.info("=" * 60)
        logger.info("ğŸš€ å¯åŠ¨ Data Doctor Ultra æ·±åº¦å·¡æ£€")
        logger.info("=" * 60)

        self.results = []
        self.missing_codes = set()
        self.corrupted_codes = set()
        self.stubborn_codes = set()

        async with get_db_session() as session:
            # 0. ç¡®å®šå¾…æ£€æŸ¥æ—¥æœŸ
            check_date = await self._get_latest_check_date(session)
            logger.info(f"å·¡æ£€ç›®æ ‡æ—¥æœŸ: {check_date}")

            # 1. åˆ†è¯Šï¼šæ£€æŸ¥è¦†ç›–ç‡
            await self._check_quote_coverage("stock", check_date, session)
            await self._check_quote_coverage("etf", check_date, session)

            # 2. åˆ†è¯Šï¼šæ·±åº¦é€»è¾‘ä½“æ£€ (Kçº¿ã€é‡çº²ã€æ³„éœ²)
            await self._check_deep_logic(check_date, session)

            # 3. æº¯æºä¸ç†”æ–­ï¼šå‰”é™¤æ— æ³•è‡ªåŠ¨ä¿®å¤çš„â€œé¡½ç–¾â€
            await self._root_cause_analysis(session)

            # 4. å…¶å®ƒæŒ‡æ ‡ç›‘æ§
            await self._check_data_freshness(session)
            await self._check_metadata_completeness(session)

            # 5. ç‰©ç†æ¸…ç†ï¼šæ¸…ç†æ— æ³•é€šè¿‡é‡åŒæ­¥è¦†ç›–çš„è„æ•°æ® (å¦‚åœç‰Œæ³„éœ²)
            await self._purge_polluted_data(check_date, session)
            await session.commit()

        # ç”ŸæˆæŠ¥å‘Š
        self._generate_report()

        # 5. æ‰§è¡Œè‡ªæ„ˆä¿®å¤ (è¡¥å½•)
        await self._auto_repair_smart()

        # 6. [æ–°å¢] å‘é€æŠ¥è­¦é‚®ä»¶ (å¦‚æœæœ‰å¼‚å¸¸)
        try:
            from app.utils.alert_service import alert_service
            alert_service.send_dqa_report(self.results, self.stubborn_codes)
        except Exception as e:
            logger.error(f"å‘é€æŠ¥è­¦é‚®ä»¶å¤±è´¥: {e}")

        logger.info("=" * 60)
        logger.info("Ultra å·¡æ£€ä»»åŠ¡æ‰§è¡Œå®Œæ¯•")
        logger.info("=" * 60)

        return self.results

    async def _root_cause_analysis(self, session):
        """æº¯æºï¼šè¯†åˆ«å¤šæ¬¡å°è¯•åä¾ç„¶å¤±è´¥çš„ä»£ç ï¼Œæ‰§è¡Œç†”æ–­"""
        all_bad = self.missing_codes | self.corrupted_codes
        if not all_bad: return

        # æŸ¥è¯¢ sync_errors è¡¨ï¼Œçœ‹è¿™äº›ä»£ç æœ€è¿‘ 24 å°æ—¶æ˜¯å¦å·²å¤±è´¥è¿‡ >= 3 æ¬¡
        stubborn_stmt = text("""
            SELECT target_code FROM sync_errors 
            WHERE created_at > NOW() - INTERVAL '24 hours'
              AND retry_count >= 3
              AND target_code = ANY(:codes)
        """)
        
        result = await session.execute(stubborn_stmt, {"codes": list(all_bad)})
        self.stubborn_codes = {row[0] for row in result.fetchall()}
        
        if self.stubborn_codes:
            # ä»ä¿®å¤åå•ä¸­å‰”é™¤
            self.missing_codes -= self.stubborn_codes
            self.corrupted_codes -= self.stubborn_codes
            
            logger.warning(f"ğŸš« ç†”æ–­ä¿æŠ¤: å‘ç° {len(self.stubborn_codes)} åªâ€˜é¡½ç–¾â€™æ ‡çš„(å¤šæ¬¡ä¿®å¤å¤±è´¥)ï¼Œå·²æ‹¦æˆªè‡ªåŠ¨åŒ–ä»»åŠ¡ã€‚")
            
            self._add_result(
                "circuit_breaker", "critical", float(len(self.stubborn_codes)), 0,
                f"âŒ ç†”æ–­æ‹¦æˆª: {len(self.stubborn_codes)} åªæ ‡çš„éœ€äººå·¥ä»‹å…¥æ’æŸ¥ä¸Šæ¸¸",
                {"stubborn_list": list(self.stubborn_codes)[:10]}
            )

    async def _purge_polluted_data(self, check_date: date, session):
        """ç‰©ç†æ¸…ç†ï¼šåˆ é™¤é‚£äº›æ— æ³•é€šè¿‡é‡æŠ“ä¿®å¤çš„æ³„éœ²æ•°æ®"""
        # è¯†åˆ«ä¸æ´»è·ƒä½†æœ‰è¡Œæƒ…çš„æ•°æ®
        leak_stmt = text(f"""
            SELECT q.code FROM daily_quotes q
            JOIN stocks s ON q.code = s.code
            WHERE q.trade_date = '{check_date}' AND s.is_active = False
        """)
        leak_codes = {row[0] for row in (await session.execute(leak_stmt)).fetchall()}
        
        if leak_codes:
            del_stmt = delete(DailyQuote).where(
                and_(DailyQuote.trade_date == check_date, DailyQuote.code.in_(list(leak_codes)))
            )
            await session.execute(del_stmt)
            logger.info(f"ğŸ§¹ ç‰©ç†æ¸…ç†: å·²ä»è¡Œæƒ…è¡¨ä¸­å‰”é™¤ {len(leak_codes)} æ¡åœç‰Œè‚¡æ³„éœ²æ•°æ®")

    async def _get_latest_check_date(self, session) -> date:
        """ä»æ•°æ®åº“æ—¥å†è·å–æœ€è¿‘ä¸€ä¸ªåº”æœ‰æ•°æ®çš„å¼€å¸‚æ—¥"""
        stmt = select(func.max(TradingCalendar.trade_date)).where(
            and_(TradingCalendar.is_open == True, TradingCalendar.trade_date < date.today())
        )
        result = await session.execute(stmt)
        latest_date = result.scalar()
        if not latest_date:
            target = date.today() - timedelta(days=1)
            while target.weekday() >= 5: target -= timedelta(days=1)
            return target
        return latest_date

    async def _check_quote_coverage(self, asset_type: str, check_date: date, session):
        """æ£€æŸ¥è¡Œæƒ…è¦†ç›–ç‡ï¼Œè®°å½•ç¼ºå¤±ä»£ç """
        all_codes_stmt = select(Stock.code).where(
            and_(Stock.asset_type == asset_type, Stock.is_active == True)
        )
        all_codes = {row[0] for row in (await session.execute(all_codes_stmt)).fetchall()}
        total_count = len(all_codes)
        if total_count == 0: return

        synced_stmt = select(DailyQuote.code).where(
            and_(DailyQuote.trade_date == check_date, DailyQuote.code.in_(list(all_codes)))
        )
        synced_codes = {row[0] for row in (await session.execute(synced_stmt)).fetchall()}
        
        missing = all_codes - synced_codes
        self.missing_codes.update(missing)

        coverage = len(synced_codes) / total_count
        status = "healthy" if coverage >= 0.98 else ("warning" if coverage >= 0.9 else "critical")
        self._add_result(
            f"{asset_type}_coverage", status, coverage, 0.95,
            f"{'âœ…' if status == 'healthy' else 'âŒ'} {asset_type.upper()} è¦†ç›–ç‡: {coverage*100:.1f}% ({len(synced_codes)}/{total_count})"
        )

    async def _check_deep_logic(self, check_date: date, session):
        """æ·±åº¦ SQL é€»è¾‘æ ¡éªŒ (å…¨é‡ä¸‹æ¨)"""
        # 1. åŸºç¡€å¼‚å¸¸å€¼
        basic_stmt = select(DailyQuote.code).where(
            and_(DailyQuote.trade_date == check_date, (DailyQuote.close <= 0) | (DailyQuote.volume < 0))
        )
        basic_err = {row[0] for row in (await session.execute(basic_stmt)).fetchall()}

        # 2. Kçº¿é€»è¾‘å†²çª
        kline_stmt = text(f"""
            SELECT code FROM daily_quotes 
            WHERE trade_date = '{check_date}' 
              AND (high < low OR close > high OR open > high OR low > open OR low > close)
        """)
        kline_err = {row[0] for row in (await session.execute(kline_stmt)).fetchall()}

        # 3. é‡ä»·é‡çº²é”™é… (100å€åç§»)
        dimension_stmt = text(f"""
            SELECT code FROM daily_quotes 
            WHERE trade_date = '{check_date}' AND volume > 0 AND amount > 0 
              AND (amount/volume < low * 0.8 OR amount/volume > high * 1.2)
        """)
        dim_err = {row[0] for row in (await session.execute(dimension_stmt)).fetchall()}

        # 4. åœç‰Œæ³„éœ²
        leak_stmt = text(f"""
            SELECT q.code FROM daily_quotes q
            JOIN stocks s ON q.code = s.code
            WHERE q.trade_date = '{check_date}' AND s.is_active = False
        """)
        leak_err = {row[0] for row in (await session.execute(leak_stmt)).fetchall()}

        self.corrupted_codes.update(basic_err | kline_err | dim_err | leak_err)
        total_err = len(self.corrupted_codes)
        status = "healthy" if total_err == 0 else "warning"
        
        self._add_result(
            "quality_logic", status, float(total_err), 0,
            f"{'âœ…' if status == 'healthy' else 'âš ï¸'} æ•°æ®é€»è¾‘è´¨é‡: å‘ç° {total_err} æ¡é€»è¾‘é”™è¯¯"
        )

    async def _check_data_freshness(self, session):
        latest_date = (await session.execute(select(func.max(DailyQuote.trade_date)))).scalar()
        target_date = await self._get_latest_check_date(session)
        if not latest_date: return
        days_diff = (target_date - latest_date).days
        status = "healthy" if latest_date >= target_date else "critical"
        self._add_result("freshness", status, float(days_diff), 0, f"{'âœ…' if status == 'healthy' else 'âŒ'} æ•°æ®æ–°é²œåº¦: æœ€æ–°æ—¥æœŸ {latest_date}")

    async def _check_metadata_completeness(self, session):
        total = (await session.execute(select(func.count(Stock.code)).where(Stock.is_active == True))).scalar() or 0
        with_industry = (await session.execute(select(func.count(Stock.code)).where(
            and_(Stock.is_active == True, Stock.industry.isnot(None), Stock.industry != "")
        ))).scalar() or 0
        ratio = with_industry / total if total > 0 else 1
        self._add_result("metadata", "healthy" if ratio >= 0.9 else "warning", ratio, 0.9, f"å…ƒæ•°æ®è¡Œä¸šè¦†ç›–ç‡ {ratio*100:.1f}%")

    def _add_result(self, name, status, value, threshold, message, details=None):
        res = HealthCheckResult(name, status, value, threshold, message, details)
        self.results.append(res)
        logger.info(message)
        return res

    def _generate_report(self):
        logger.info("\n" + "="*40 + "\nğŸ“Š Data Doctor Ultra å·¡æ£€æŠ¥å‘Š\n" + "="*40)
        for r in self.results:
            logger.info(f"[{r.status.upper():<8}] {r.message}")
        logger.info("="*40)

    async def _auto_repair_smart(self):
        """æ™ºèƒ½è‡ªæ„ˆï¼šä¸‹å‘è¡¥å½•ä»»åŠ¡"""
        all_to_fix = list(self.missing_codes | self.corrupted_codes)
        if not all_to_fix: return
        logger.info(f"ğŸ”§ å¯åŠ¨è‡ªæ„ˆä¿®å¤: å¾…ä¿®å¤æ ‡çš„ {len(all_to_fix)} åª")
        try:
            from app.tasks.sync_tasks import sync_daily_quotes
            chunk_size = 100
            for i in range(0, len(all_to_fix), chunk_size):
                chunk = all_to_fix[i : i + chunk_size]
                sync_daily_quotes.delay(codes=chunk, is_chunk=True)
            logger.info(f"ğŸš€ å·²ä¸‹å‘ {len(all_to_fix)} åªæ ‡çš„çš„è‡ªæ„ˆåˆ†ç‰‡ä»»åŠ¡")
        except Exception as e:
            logger.error(f"âŒ è‡ªæ„ˆä»»åŠ¡ä¸‹å‘å¤±è´¥: {e}")


# è¿è¡Œå…¥å£
async def run_dqa():
    doctor = DataDoctor()
    return await doctor.run_daily_health_check()

if __name__ == "__main__":
    import asyncio
    asyncio.run(run_dqa())
